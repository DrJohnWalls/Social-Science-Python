{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART ONE - Advanced CSV Manipulation - The Power of the DataFrame\n",
    "# csv.reader and writer are fine for more basic manipulations - but for more advanced, we need pandas!\n",
    "import pandas as pd # the 'as' just means that we get to call pandas 'pd' in our code\n",
    "import numpy as np # Numpy is a really nifty library!\n",
    "\n",
    "df = pd.read_csv(\"real_loan_data.csv\", index_col='id')\n",
    "\n",
    "# Now we have our DataFrame object! \n",
    "# If you need it to be printed in the middle of other code, you must print it out as a raw table by using print()\n",
    "df.head(5)\n",
    "# While you can just say df, the .head() method ensures only the first N rows are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[:-3]\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also print out some basic information about your DataFrame\n",
    "\n",
    "print(df.columns)\n",
    "print(len(df.columns))\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy: Really Cool Number Manipulations!!\n",
    "# Numpy 1\n",
    "\n",
    "my_list = np.random.randn(10,4)\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy 2: DataFrames Like Numpy!\n",
    "df_random = pd.DataFrame(np.random.randn(10,4))\n",
    "df_random.to_csv(\"my_csv.csv\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy 3: arange and reshape\n",
    "a = np.arange(15).reshape(3, 5)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.ndim)\n",
    "b = np.array([6, 7, 8])\n",
    "# Numpy Array vs Python List - which should I use?\n",
    "# Basics: Numpy Array are computationally faster and take up less memory, but you lose a lot of Python's cool methods\n",
    "# and flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy 4: Mass-create matrixes of Zeroes and Ones\n",
    "print(np.zeros( (3,4) ))\n",
    "print(np.ones( (3,4) ))\n",
    "print(np.arange( 10, 30, 5 ))\n",
    "print(np.linspace( 0, 2, 9 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also rename just a single column. But, take special note of inplace below!! An Optional Parameter!\n",
    "# Inplace=True means that you OVERWRITE the OLD dataframe with the NEW one.\n",
    "# By default, inplace is false, and that means it creates a DataFrame copy with your change in it\n",
    "# Some pandas methods don't have an inplace parameter - for those, most make a new dataframe\n",
    "\n",
    "# Look closely - this will really trip you up if you don't pay attention!\n",
    "# Without using inplace, you need to assign df to a new variable.\n",
    "df2 = df.rename(columns={'issue_d': 'issued_date'})\n",
    "\n",
    "# Using inplace, you can just run it on its own (not setting it equal to anything) and it will overwrite\n",
    "df.rename(columns={'sub_grade': 'mini_grade'}, inplace=True)\n",
    "print(df2.head(5))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inserting new columns is also really easy\n",
    "new_dataframe = pd.DataFrame(columns=['Dummy','B'])\n",
    "df = pd.concat([df,new_dataframe])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all those NaN with whatever you want.\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To insert/update rows, you can do it either with indexes or with string names (if the rows are named).\n",
    "df.loc[0] = [2,3,4,5,\"1 day\",1,1,1,1,1,1,1,1,1] # This will update the first row always\n",
    "df.loc['Silly'] = [2,3,4,5,\"1 day\",1,1,1,1,1,1,1,1,1] # This will write a new row since a row named \"Silly\" doesn't exist\n",
    "df.loc[len(df)] = [32,3,4,5,\"4 days\",1,21,1,1,38,87,45,1,1]\n",
    "# However, note that you need to have the same number of rows in your list as there are rows in the DataFrame\n",
    "print(df.head(5))\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To delete a row or column, there's just a single method\n",
    "# The key is the axis parameter - 0 means that it's a row, 1 means that it's a column\n",
    "if 'Dummy' in df.columns: # If there is a Dummy column...\n",
    "    df.drop('Dummy', axis=1, inplace=True) # Drop it from the columns, since axis is 1\n",
    "if 'Silly' in df.index: # If there is a row at index 2...\n",
    "    df.drop('Silly', axis=0, inplace=True) # Drop the row at index 'Silly' from the rows, since axis is 0\n",
    "print('Dummy' in df.columns)\n",
    "print('Silly' in df.index)\n",
    "df.head(5) #AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's also very easy to swap rows and columns\n",
    "df_new = df.transpose() #They didn't include an inplace parameter for the transpose method. You MUST make a new one\n",
    "print(df.head(5))\n",
    "print(df_new.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also edit individual cells via the set_value() method\n",
    "df = df.set_value(\"54734\", 'issue_d', '11-Aug')\n",
    "# First value is the row index (X), second value is the column name (Y), third value is what to insert\n",
    "# Unless you're editing a whole row or column in one line, this is the preferred way to edit a single cell\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['54345']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fancy Tricks! \n",
    "# Trick 1:\n",
    "# Pandas extends Python's slicing capabilities with their DataFrame objects to allow for STATA/R-like editing\n",
    "# The below statement does this: \n",
    "\n",
    "# For each row in df, check if the loan_status column is NOT equal to \"Fully Paid\". \n",
    "# When it is NOT EQUAL, modify the associated 'term' column to the value 'one million months'\n",
    "# If it's not, leave it unchanged\n",
    "\n",
    "df.loc[df['loan_status'] != \"Fully Paid\", 'term'] = 'one million months'\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 2: Print out only certain columns/rows based on conditions\n",
    "\n",
    "df_new = df.loc[(df[\"loan_amnt\"] > 25000) & (df[\"loan_status\"] != \"Fully Paid\") & (df[\"grade\"] != \"A\"), \n",
    "                [\"member_id\",\"loan_amnt\",\"loan_status\",\"grade\"]]\n",
    "# Note that here I'm not actually modifying any values, although I could. Rather, I'm just displaying a select chunk of\n",
    "# the spreadsheet\n",
    "print(df_new.head(5))\n",
    "\n",
    "df_new = df.loc[((df[\"loan_amnt\"] < 25000) & (df[\"loan_amnt\"] > 30000)) \n",
    "                & (df[\"loan_status\"] != \"Fully Paid\") & (df[\"grade\"] != \"A\")]\n",
    "print(df_new.head(5))\n",
    "\n",
    "# Looking above, you may ask, why are you using & and not 'and'? (You also use | instead of 'or')\n",
    "# The difference between & and \"and\" is a pretty complex topic without much meaning to social scientists\n",
    "# If you're REALLY just that curious, research short-circuiting boolean operators.\n",
    "# What you DO need to know is that whenever you're inside square brackets [], you need to use &/| intead of and/or.\n",
    "# The 'and' statement will NOT function properly inside square brackets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['member_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 3: Applying functions to individual columns (also works for individual rows or all columns or all rows)\n",
    "def p2f(x):\n",
    "    if x == 10:\n",
    "        return x\n",
    "    else:\n",
    "        return x-5\n",
    "#pd.options.display.max_columns = 40\n",
    "# Note that you can also use lambda functions inside the apply method. However, for more complex operations,\n",
    "# creating a whole new function is often best\n",
    "df['int_rate'] = df['int_rate'].apply(p2f)\n",
    "df['int_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 4: Printing out crosstabs\n",
    "tab = pd.crosstab(df[\"mini_grade\"],df[\"int_rate\"],margins=True)\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 5: The Power of GroupBy\n",
    "\n",
    "# First, force the column to be numeric\n",
    "df['int_rate'] = pd.to_numeric(df['int_rate'],errors='coerce')\n",
    "# Other than 'coerce, there is also 'raise' and 'ignore'\n",
    "# 'raise' makes Python give an error if it can't convert a value to a numeric value\n",
    "# 'ignore' just does nothing to the entire column if it finds a single error, but doesn't alert you\n",
    "\n",
    "# Now use the power of GroupBy to do amazing things!\n",
    "my_groups = df['int_rate'].groupby(df['grade'])\n",
    "print(my_groups.describe())\n",
    "print(my_groups.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finally, you can spit your DataFrame out as a CSV with one line\n",
    "df.to_csv(\"your_spreadsheet.csv\")\n",
    "tab.to_csv(\"your_crosstab.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
