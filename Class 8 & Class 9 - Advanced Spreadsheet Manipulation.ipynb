{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CLASS 8 + 9: Advanced Spreadsheet Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART ONE - Advanced CSV Manipulation - The Power of the DataFrame\n",
    "# If you're familiar with R, this should be familiar\n",
    "\n",
    "# csv.reader and csv.writer are fine for basic manipulations - but for more advanced, we need pandas!\n",
    "\n",
    "import pandas as pd # the 'as' just means that we get to call pandas 'pd' in our code\n",
    "\n",
    "# The read_csv function in the pandas library grabs a CSV file nice and quick.\n",
    "# It puts it into a DataFrame object\n",
    "df = pd.read_csv(\"Input Files/Presidential Proclamations, 1789-2016.csv\")\n",
    "\n",
    "# Now we have our DataFrame object, affectionately named df \n",
    "print(df.head(5))\n",
    "# While you could just do print(df), the .head(N) method ensures only the first N rows are displayed.\n",
    "# Telling Jupyter Notebook to load over 7,000 rows takes a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why use Pandas?\n",
    "# Using csv.reader/writer can be simpler at first\n",
    "# However, when moving beyond anything but the most basic modifications of data,\n",
    "# Pandas very quickly surpasses csv.reader/writer in functionality\n",
    "# That being said, it does have a learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the LAST 5 rows instead\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can use list slicing on DataFrames - this cuts off the last 3 rows from the bottom, and stores this newly sliced\n",
    "# DataFrame in df_2\n",
    "df_2 = df[:-3]\n",
    "print(df_2.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also print out some basic information about your DataFrame\n",
    "\n",
    "# The names of the columns\n",
    "print(df.columns)\n",
    "# How many columns exist\n",
    "print(len(df.columns))\n",
    "# How many rows exist\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also rename just a single column. But, take special note of inplace below, an optional parameter\n",
    "# inplace=True means that you OVERWRITE the OLD dataframe with the NEW one.\n",
    "# By default, inplace is false, and that means Python creates a DataFrame copy with your change in it\n",
    "# Sometimes you'll want to keep your old dataframe, other times you'll want to overwrite it.\n",
    "# Some pandas methods don't have an inplace parameter - for those, most make a new dataframe\n",
    "\n",
    "# Look closely - this will trip you up later if you don't pay special attention.\n",
    "# Without using inplace, you need to assign df to a new variable.\n",
    "df2 = df.rename(columns={'date': 'date_of_issuance'})\n",
    "\n",
    "# Using inplace, you can just run it on its own (not setting it equal to anything) and it will overwrite itself\n",
    "df.rename(columns={'President': 'President_In_Office'}, inplace=True)\n",
    "\n",
    "# Let's check out the difference?\n",
    "print(df2.head(5))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inserting new columns is also easy\n",
    "new_dataframe = pd.DataFrame(columns=['Dummy','B'])\n",
    "\n",
    "# concat() comes from concatenate. Just as you might concatenate strings,\n",
    "# Python lets you concatenate DataFrames together\n",
    "df_new = pd.concat([df,new_dataframe])\n",
    "\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all 'empty' values (what Pandas calls NaN values) with the specified value of your choice\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To insert/update rows, you can do it either with indexes or with string names (if the rows are named).\n",
    "# This will update (i.e. overwrite) the first row\n",
    "df.loc[0] = [\"John Doe\",\"January 1st, 1900\",\"A Random Proclamation\",\"http://google.com\"] \n",
    "\n",
    "# This will write a new row since a row named \"Silly\" doesn't exist\n",
    "df.loc['Silly'] = [\"John Doe\",\"January 1st, 1900\",\"A Random Proclamation\",\"http://google.com\"]\n",
    "\n",
    "# This always adds a row to the very end.\n",
    "df.loc[len(df)] = [\"John Doe\",\"January 1st, 1900\",\"A Random Proclamation\",\"http://google.com\"]\n",
    "\n",
    "# However, note that you need to have the same number of rows in your list as there are rows in the DataFrame\n",
    "print(df.head(5))\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To delete a row or column, there's just a single method\n",
    "# The key is the axis parameter - 0 means that it's a row, 1 means that it's a column\n",
    "# Here we use the df.columns list that we saw earlier.\n",
    "if 'Dummy' in df.columns: # If there is a Dummy column...\n",
    "    df.drop('Dummy', axis=1, inplace=True) # Drop it from the columns, since axis is 1\n",
    "if 'Silly' in df.index: # If there is a row at index 2...\n",
    "    df.drop('Silly', axis=0, inplace=True) # Drop the row at index 'Silly' from the rows, since axis is 0\n",
    "print('Dummy' in df.columns) # Returns True or False, depending on if 'Dummy' is the name of a column in df\n",
    "print('Silly' in df.index)\n",
    "print(df.head(5)) #AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's also very easy to swap rows and columns, although it makes little sense for this specific dataset\n",
    "df_new = df.transpose() #They didn't include an inplace parameter for the transpose method. You MUST make a new one\n",
    "print(df.head(5))\n",
    "print(df_new.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also edit individual cells via the set_value() method. \n",
    "# Row, Column, Value\n",
    "df.set_value(\"2000\", 'President', 'John Doe')\n",
    "\n",
    "# And you can grab individual cells via the get_value() method\n",
    "# Row, Column\n",
    "my_value = df.get_value(\"2000\", 'President')\n",
    "# First value is the row index (X), second value is the column name (Y), third value is what to insert\n",
    "# Unless you're editing a whole row or column in one line, this is the preferred way to edit a single cell\n",
    "print(my_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Useful Tips and Tricks\n",
    "\n",
    "# Trick 1:\n",
    "# Pandas extends Python's slicing capabilities with their DataFrame objects to allow for STATA/R-like editing\n",
    "# Check out what's below\n",
    "i_like_prez = [\"George Washington\",\"John Adams\",\"Thomas Jefferson\"]\n",
    "df_only = df.loc[df['President_In_Office'].isin(i_like_prez)]\n",
    "\n",
    "# Inside df.loc, not only can you give it an index number or a name of a row (if it's named)\n",
    "# You can also insert special pandas functions in it.\n",
    "# What the above code does is it creates a new DataFrame containing only those rows where the\n",
    "# 'President_In_Office' column is among the list provided.\n",
    "df_only.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 2: More advanced slicing\n",
    "\n",
    "# You can have multiple conditions - in this one, df_new will only contain rows with the proper President\n",
    "# AND the proper year.\n",
    "df_new = df.loc[(df[\"President_In_Office\"].isin(i_like_prez) & (df['Date'].str.endswith(\"1795\")))]\n",
    "print(df_new.head(5))\n",
    "\n",
    "# Looking above, you may ask, \"why are you using & and not 'and'?\" (You also use | instead of 'or')\n",
    "# The difference between & and \"and\" is a pretty complex topic without much meaning to social scientists\n",
    "# If you're REALLY just that curious, research \"short-circuiting boolean operators\".\n",
    "# What's important to know is that whenever you're inside square brackets [], you need to use &/| intead of and/or.\n",
    "# The 'and' statement will NOT function properly inside square brackets! Nor will 'or'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 3: Applying functions to individual columns (also works for individual rows or all columns or all rows)\n",
    "\n",
    "# Let's say we wanted to modify the Date column in a complex way - to remove all the information\n",
    "# except for the year. There's an easy way to apply a function to every row with just a few lines of code\n",
    "\n",
    "# First, let's define a function. The \"x\" parameter will be the content of each cell.\n",
    "def year_only(x):\n",
    "    split_date = str(x).split(\", \")\n",
    "    # We have to make sure that the Date actually exists - some dates might be in a bad format.\n",
    "    if len(split_date) > 1:\n",
    "        # The below function will ensure that only the year is returned\n",
    "        return str(x).split(\", \")[1]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Finally, we use the apply() method to apply a function that we've created to each cell within the column\n",
    "# Note that we're not writing year_only(x), just year_only\n",
    "# This is because you're actually passing the function itself into the apply() function\n",
    "df['Date'] = df['Date'].apply(year_only)\n",
    "print(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trick 4: Printing out crosstabs\n",
    "tab = pd.crosstab(df[\"President_In_Office\"],df[\"Date\"],margins=True)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finally, you can send your DataFrame out as a CSV with one line\n",
    "# The index=False parameter (optional) means that I don't want Python to generate an\n",
    "# extra index column for me from 0 onward. But sometimes you would like an index column to be created\n",
    "df.to_csv(\"Output Files/your_spreadsheet.csv\",index=False)\n",
    "tab.to_csv(\"Output Files/your_crosstab.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NUMPY: Python's Number-manipulation package\n",
    "import numpy as np # numpy is highly useful for quickly creating, processing, and storing numerical data\n",
    "# You aren't required to write \"as np\", but it's considered a standard Python naming convention\n",
    "# instead of writing numpy.something or numpy.that, you can write np.something or np.that.\n",
    "# Numpy has a number of useful utilities\n",
    "# Numpy uses an object called an array, which is quite similar to the Python list except that it's specically made\n",
    "# to process numerical data quickly and to apply mathematical functions quickly\n",
    "\n",
    "# Numpy 1: make a 10x4 \"array of arrays\" (i.e. a list of lists, or a spreadsheet) of numbers in a normal distribution\n",
    "my_list = np.random.randn(10,4)\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy 1a: Applying math functions to every value in a numpy array\n",
    "# The fascinating part about numpy is that you can easily apply math functions to all elements.\n",
    "# For example, dividing by two actually divides every element in the 10x4 list by two. Same with multiplying\n",
    "my_list = np.random.randn(10,4)\n",
    "print(my_list)\n",
    "list_2 = my_list*10\n",
    "print(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy 1b: What if we wanted to go from -1 to 1 instead of a normal distribution\n",
    "my_array = np.random.randint(0,100,20)/100\n",
    "print(my_array)\n",
    "\n",
    "# Let's transform it from 20x1 into a 4x5 array\n",
    "my_array = my_array.reshape((4,5))\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy 2: Pandas Likes Numpy\n",
    "# Pandas' DataFrame function can accept a numpy-created array to create a new DataFrame\n",
    "df_random = pd.DataFrame(np.random.randn(10,4))\n",
    "print(df_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy 3: arange and reshape\n",
    "\n",
    "a = np.arange(15)\n",
    "# a = range(0,15) basically produces the same result\n",
    "# Why use arange then? See below...\n",
    "\n",
    "# The whole numpy array\n",
    "print(a)\n",
    "# the \"shape\" of the numpy array\n",
    "print(a.shape)\n",
    "# the number of dimensions in the numpy array\n",
    "print(a.ndim)\n",
    "\n",
    "# reshape transforms a 1-dimensional array into a 2-dimensional array\n",
    "a = a.reshape(3, 5)\n",
    "print(\"Reshaped:\")\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy 4: Python Lists vs Numpy Arrays: Which to Use?\n",
    "\n",
    "numpy_array = np.array([6, 7, 8, 9])\n",
    "print(numpy_array)\n",
    "python_list = [6,7,8,9]\n",
    "print(python_list)\n",
    "# Basics: Numpy arrays are computationally faster and take up less memory.\n",
    "# However, you lose a lot of Python's useful methods and flexibility\n",
    "# For instance, numpy arrays should only have one TYPE of object in them.\n",
    "# If you use multiple types, numpy will attempt to forcibly change their\n",
    "# types to match.\n",
    "\n",
    "# What does this mean for you?\n",
    "# If you're after blazing fast speed for larger datasets, use numpy arrays\n",
    "# If you're after flexibility and fancy functions and methods, use Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy 5: Mass-create 2D arrays of various types\n",
    "print(np.zeros((3,4)))\n",
    "print(\"----------------------\")\n",
    "print(np.ones((3,4)))\n",
    "print(\"----------------------\")\n",
    "print(np.arange(10, 30, 5))\n",
    "print(\"----------------------\")\n",
    "print(np.linspace(0, 2, 9))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
